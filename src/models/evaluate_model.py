import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import joblib
import os
import sys
from tqdm import tqdm

# Import config & modules
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../../')))
import src.config as config
from src.models.model import TimeSeriesTransformer
from src.data.data_loader import get_data_loaders


def inverse_transform_target(pred_scaled, actual_scaled, scaler, target_idx):
    """H√†m gi·∫£i m√£ (Un-scale) gi√° tr·ªã v·ªÅ ƒë∆°n v·ªã M√©t"""
    # pred_scaled shape: [N, 1] ho·∫∑c [N]
    # T·∫°o ma tr·∫≠n gi·∫£ ƒë·ªÉ l·ª´a scaler inverse
    n_samples = len(pred_scaled)
    n_features = len(config.FEATURE_COLUMNS)

    dummy_pred = np.zeros((n_samples, n_features))
    dummy_actual = np.zeros((n_samples, n_features))

    dummy_pred[:, target_idx] = pred_scaled.flatten()
    dummy_actual[:, target_idx] = actual_scaled.flatten()

    inv_pred = scaler.inverse_transform(dummy_pred)[:, target_idx]
    inv_actual = scaler.inverse_transform(dummy_actual)[:, target_idx]

    return inv_pred, inv_actual


def evaluate_full_test_set():
    print("--- B·∫ÆT ƒê·∫¶U ƒê√ÅNH GI√Å TO√ÄN DI·ªÜN (FULL TEST SET) ---")
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # 1. Load Data & Scaler
    # Ch√∫ng ta c·∫ßn load l·∫°i DataFrame g·ªëc ƒë·ªÉ l·∫•y ng√†y th√°ng chu·∫©n x√°c
    df_full = pd.read_csv(config.FINAL_TRAIN_FILE, parse_dates=['ThoiGianCapNhat'], index_col='ThoiGianCapNhat')
    split_idx = int(len(df_full) * config.SPLIT_RATIO)
    val_df_orig = df_full.iloc[split_idx:]  # ƒê√¢y l√† t·∫≠p Validation g·ªëc (c√≥ ng√†y th√°ng)

    # Load Loader & Scaler
    _, val_loader, _ = get_data_loaders()
    scaler = joblib.load(config.SCALER_SAVE_PATH)
    target_idx = config.FEATURE_COLUMNS.index(config.TARGET_COLUMN)

    # 2. Load Model
    # L·∫•y 1 m·∫´u ƒë·ªÉ bi·∫øt s·ªë features input
    sample_x, _ = next(iter(val_loader))
    model = TimeSeriesTransformer(
        num_features=sample_x.shape[2],
        d_model=config.D_MODEL,
        nhead=config.N_HEADS,
        num_encoder_layers=config.NUM_ENCODER_LAYERS,
        dim_feedforward=config.DIM_FEEDFORWARD,
        dropout=config.DROPOUT_RATE,
        input_window=config.INPUT_WINDOW_DAYS,
        output_window=config.OUTPUT_WINDOW_DAYS
    ).to(device)

    if os.path.exists(config.MODEL_SAVE_PATH):
        model.load_state_dict(torch.load(config.MODEL_SAVE_PATH, map_location=device))
        print("‚úÖ ƒê√£ load model th√†nh c√¥ng!")
    else:
        print("‚ùå Kh√¥ng t√¨m th·∫•y file model.pth")
        return

    model.eval()

    # 3. Ch·∫°y D·ª± b√°o tr√™n TO√ÄN B·ªò t·∫≠p Test (V√≤ng l·∫∑p)
    all_preds = []
    all_actuals = []

    print("üìä ƒêang ch·∫°y d·ª± b√°o tr√™n to√†n b·ªô t·∫≠p Test...")
    with torch.no_grad():
        for X_batch, y_batch in tqdm(val_loader):
            X_batch = X_batch.to(device)
            # Output: [Batch, 7, 1]
            y_pred = model(X_batch)

            all_preds.append(y_pred.cpu().numpy())
            all_actuals.append(y_batch.cpu().numpy())

    # G·ªôp t·∫•t c·∫£ c√°c batch l·∫°i
    # Shape sau khi g·ªôp: [T·ªïng_s·ªë_m·∫´u, 7, 1]
    all_preds = np.concatenate(all_preds, axis=0)
    all_actuals = np.concatenate(all_actuals, axis=0)

    # 4. T√≠nh to√°n Metrics (ƒê√°nh gi√° ƒë·ªô ch√≠nh x√°c)
    # ƒê·ªÉ ƒë√°nh gi√° t·ªïng qu√°t, ta s·∫Ω so s√°nh "D·ª± b√°o ng√†y k·∫ø ti·∫øp" (Lead time 1)
    # T·ª©c l√†: ƒê·ª©ng ·ªü h√¥m nay, d·ª± b√°o ng√†y mai (Ng√†y 1 trong chu·ªói 7 ng√†y)

    # L·∫•y ng√†y ƒë·∫ßu ti√™n trong chu·ªói d·ª± b√°o 7 ng√†y (Day 1 forecast)
    pred_lead1 = all_preds[:, 0, 0]
    actual_lead1 = all_actuals[:, 0, 0]

    # Gi·∫£i m√£ v·ªÅ ƒë∆°n v·ªã M√©t
    pred_m, actual_m = inverse_transform_target(pred_lead1, actual_lead1, scaler, target_idx)

    # T√≠nh ch·ªâ s·ªë
    rmse = np.sqrt(mean_squared_error(actual_m, pred_m))
    mae = mean_absolute_error(actual_m, pred_m)
    r2 = r2_score(actual_m, pred_m)

    print("\n" + "=" * 40)
    print("K·∫æT QU·∫¢ ƒê√ÅNH GI√Å (D·ª∞ B√ÅO NG√ÄY K·∫æ TI·∫æP)")
    print("=" * 40)
    print(f"üìâ RMSE (Sai s·ªë chu·∫©n): {rmse:.4f} m")
    print(f"üìâ MAE (Sai s·ªë tuy·ªát ƒë·ªëi): {mae:.4f} m")
    print(f"üìà R2 Score (ƒê·ªô ph√π h·ª£p): {r2:.4f} (C√†ng g·∫ßn 1 c√†ng t·ªët)")
    print("=" * 40)

    # 5. V·∫Ω bi·ªÉu ƒë·ªì "Continuous" (Li√™n t·ª•c theo th·ªùi gian)
    # C·∫ßn l·∫•y ƒë√∫ng ng√†y th√°ng t∆∞∆°ng ·ª©ng.
    # T·∫≠p Val loader b·∫Øt ƒë·∫ßu c·∫Øt t·ª´: Input Window.
    # N√™n ƒëi·ªÉm d·ª± b√°o ƒë·∫ßu ti√™n s·∫Ω t∆∞∆°ng ·ª©ng v·ªõi ng√†y th·ª© (Input_Window) trong t·∫≠p Val DF

    valid_dates = val_df_orig.index[config.INPUT_WINDOW_DAYS: config.INPUT_WINDOW_DAYS + len(pred_m)]

    plt.figure(figsize=(15, 7))

    # V·∫Ω ƒë∆∞·ªùng Th·ª±c t·∫ø
    plt.plot(valid_dates, actual_m, label='Th·ª±c t·∫ø (Actual)', color='blue', linewidth=1.5)

    # V·∫Ω ƒë∆∞·ªùng D·ª± b√°o (Lead 1)
    plt.plot(valid_dates, pred_m, label='D·ª± b√°o (Predicted - Lead 1)', color='red', linestyle='--', linewidth=1.5,
             alpha=0.8)

    # Format Tr·ª•c ng√†y th√°ng
    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%d/%m/%Y'))
    plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=15))  # C√°ch 15 ng√†y hi·ªán 1 l·∫ßn
    plt.gcf().autofmt_xdate()  # Xoay ch·ªØ cho d·ªÖ ƒë·ªçc

    plt.title(f'D·ª± b√°o M·ª±c n∆∞·ªõc h·ªì tr√™n T·∫≠p Ki·ªÉm Th·ª≠ (RMSE: {rmse:.3f}m)')
    plt.ylabel('M·ª±c n∆∞·ªõc (m)')
    plt.xlabel('Th·ªùi gian')
    plt.legend()
    plt.grid(True, alpha=0.3)

    # L∆∞u ·∫£nh
    save_path = config.PROJECT_ROOT / "evaluation_full_test.png"
    plt.savefig(save_path)
    print(f"\n‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì to√†n c·∫£nh t·∫°i: {save_path}")
    plt.show()


if __name__ == "__main__":
    evaluate_full_test_set()